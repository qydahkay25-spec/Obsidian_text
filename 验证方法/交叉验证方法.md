#### 十折交叉检验

十折交叉检验是最常用的通用交叉验证方法，核心是将数据分 10 组轮流训练测试，平衡效率与稳定性。

把数据集随机平均划分为 10 个等规模子集（每组称为 1 个 “折”），通过 10 轮训练与测试完成模型评估，最终取 10 轮性能的平均值作为结果。
##### 关键特点

- **优势**：计算效率高（仅 10 轮），结果稳定性强，能有效平衡偏差与方差，避免过拟合导致的评估失真。
- **适用场景**：绝大多数机器学习任务（分类、回归均可），尤其适合中等规模数据（几百到几万样本），是科研（如论文中 CNN-PLS 模型验证）和工程落地的首选方案。
- **注意事项**：划分前需随机打乱数据，避免分组偏差；若数据类别不平衡（如分类任务），可采用 “分层十折交叉检验”，确保每折的类别分布与原始数据一致。

#### 留一法

留一法（LOO）是交叉验证中偏差最小的方法，核心是每次只留 1 个样本当测试集，剩余全为训练集，逐一轮换完成评估。

无需提前分组，将数据集中的每个样本依次单独作为测试集，剩余所有样本作为训练集，共进行 N 轮（N 为样本总数）训练与测试，最终取 N 轮性能的平均值作为模型评估结果。
##### 关键特点

- **优势**：偏差极小，几乎利用了全部数据进行训练，能最大程度反映模型的真实泛化能力；无需随机划分数据，评估结果具有唯一性（无随机误差）。
- **适用场景**：小样本数据（如几十到几百个样本），例如稀有污染事件的光谱数据、小众领域的实验数据，此时大比例训练集能保证模型训练效果。
- **局限性**：计算成本极高，样本量越大耗时越长（1000 个样本需训练 1000 次模型）；对大样本数据（如上万样本）完全不适用，效率远低于十折交叉检验。
- **注意事项**：仅适用于数据标注成本高、样本稀缺的场景，普通任务中无需优先选择；若数据存在极端异常值，可能导致单轮结果波动，但平均值仍具参考性。

#### 9 折交叉验证

